# -*- coding: utf-8 -*-
"""eating_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NaUg4UN-oUL3ilApqoj-X35mI2DeN5fr
"""

# pip install pandas opencv-python scikit-learn tensorflow pillow

import pandas as pd

# Load Excel sheet with annotations
data = pd.read_csv("/content/drive/MyDrive/eating_detection/annotations (4).csv")

print(data)

import cv2
import numpy as np
import os

# Define image size for resizing (e.g., 128x128)
IMG_SIZE = 128

def load_images_and_labels(data):
    images = []
    labels = []

    for index, row in data.iterrows():
        img_path = os.path.join('/content/drive/MyDrive/eating_detection/joel_photos', row['File'])  # Adjust path as necessary
        img = cv2.imread(img_path)

        if img is not None:
            # Resize the image to a consistent size
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            images.append(img)
            labels.append(row['Food/No Food'])

    # Convert lists to numpy arrays for model input
    X = np.array(images)
    y = np.array(labels)

    return X, y

X, y = load_images_and_labels(data)
print(f"Loaded {len(X)} images.")

from sklearn.model_selection import train_test_split

# Normalize the image data by dividing by 255 (since pixel values range from 0 to 255)
X = X / 255.0

# Split data: 80% for training, 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set: {len(X_train)} images")
print(f"Testing set: {len(X_test)} images")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

# Flatten the image data for logistic regression (convert from 128x128x3 to 1D)
X_train_flat = X_train.reshape(len(X_train), -1)
X_test_flat = X_test.reshape(len(X_test), -1)

# Train logistic regression model
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_flat, y_train)

# Make predictions
y_pred_logreg = logreg.predict(X_test_flat)

# Calculate F1 score
f1_logreg = f1_score(y_test, y_pred_logreg)
print(f"Logistic Regression F1 Score: {f1_logreg:.4f}")

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_flat, y_train)

# Make predictions
y_pred_rf = rf.predict(X_test_flat)

# Calculate F1 score
f1_rf = f1_score(y_test, y_pred_rf)
print(f"Random Forest F1 Score: {f1_rf:.4f}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Build a simple CNN model
cnn = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])

# Compile the model
cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the CNN model
cnn.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Evaluate the model and calculate F1 score
y_pred_cnn = (cnn.predict(X_test) > 0.5).astype("int32")
f1_cnn = f1_score(y_test, y_pred_cnn)
print(f"CNN F1 Score: {f1_cnn:.4f}")

print(f"Logistic Regression F1 Score: {f1_logreg:.4f}")
print(f"Random Forest F1 Score: {f1_rf:.4f}")
print(f"CNN F1 Score: {f1_cnn:.4f}")

import joblib

# Save the Random Forest model
joblib.dump(rf, 'random_forest_model.pkl')

print("Random Forest model saved as random_forest_model.pkl")

# pip install Flask